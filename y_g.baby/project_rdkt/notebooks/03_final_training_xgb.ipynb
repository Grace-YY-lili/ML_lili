{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39381aeac9744a4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T09:18:00.179926Z",
     "iopub.status.busy": "2026-01-25T09:18:00.179926Z",
     "iopub.status.idle": "2026-01-25T09:18:01.911083Z",
     "shell.execute_reply": "2026-01-25T09:18:01.911083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ [03] XGB Final Training (Robust Mode) | cwd = D:\\HO\\my_smiles_project\\y_g.baby\\project_rdkt\n",
      "   Train: (105, 126) | Val: (23, 126) | Test: (23, 126)\n",
      "\n",
      "ğŸ”§ å½“å‰ç­–ç•¥: ã€ROBUSTã€‘\n",
      "\n",
      "ğŸ§  Final Params:\n",
      "{\n",
      "  \"max_depth\": 3,\n",
      "  \"learning_rate\": 0.01,\n",
      "  \"colsample_bytree\": 0.5,\n",
      "  \"reg_alpha\": 1.0\n",
      "}\n",
      "\n",
      ">>> Training with EarlyStopping on VAL ...\n",
      "[0]\tvalidation_0-rmse:1.64639\tvalidation_1-rmse:1.63380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\tvalidation_0-rmse:0.50312\tvalidation_1-rmse:0.97196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[787]\tvalidation_0-rmse:0.37237\tvalidation_1-rmse:0.95610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Done. Best Iteration: 737\n",
      "\n",
      "========================================\n",
      "ğŸ“Š Performance (Robust Mode)\n",
      "   Train: 0.9453\n",
      "   Val  : 0.6618\n",
      "   Test : 0.6375\n",
      "========================================\n",
      "\n",
      "ğŸ§ Top 10 Features Used by Model:\n",
      "                Feature  Importance\n",
      "       NumAromaticRings    0.052235\n",
      "              PEOE_VSA1    0.051602\n",
      "              PEOE_VSA6    0.040516\n",
      "NumAromaticHeterocycles    0.036689\n",
      "       MinPartialCharge    0.035000\n",
      "              RingCount    0.030044\n",
      "               fr_Al_OH    0.028326\n",
      "           FractionCSP3    0.026873\n",
      "                    Ipc    0.023033\n",
      "                 AvgIpc    0.022634\n",
      "\n",
      "ğŸ’¾ é¢„æµ‹ç»“æœå·²ä¿å­˜ã€‚\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# File: project_rdkt/notebooks/03_final_training_xgb.py\n",
    "# ==========================================\n",
    "# [RDKit ä¸“å±] XGBoost æœ€ç»ˆè®­ç»ƒ (V3: ç¨³å¥ç­–ç•¥ç‰ˆ)\n",
    "# ç­–ç•¥è°ƒæ•´:\n",
    "# ä¹‹å‰ \"Strict\" (Depth=2) æ¬ æ‹Ÿåˆï¼Œ\"Balanced\" (Depth=4) æ•ˆæœå˜å·®ã€‚\n",
    "# ç°åœ¨åˆ‡æ¢åˆ° \"Robust\" æ¨¡å¼:\n",
    "# 1. Depth=3 (åŒ–å­¦æ•°æ®çš„é»„é‡‘æ·±åº¦)\n",
    "# 2. LR=0.01 (æ…¢å·¥å‡ºç»†æ´»)\n",
    "# 3. ColSample=0.5 (å¢åŠ éšæœºæ€§ï¼Œå¼ºè¿«æ¨¡å‹å¤šè§’åº¦è§‚å¯Ÿ)\n",
    "\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "# from xgboost.callback import EarlyStopping\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 0) ç¯å¢ƒå®šä½\n",
    "# ----------------------------------------------------------\n",
    "if 'notebooks' in os.getcwd():\n",
    "    os.chdir('..')\n",
    "print(f\"ğŸš€ [03] XGB Final Training (Robust Mode) | cwd = {os.getcwd()}\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 1) æ•°æ®è¯»å–\n",
    "# ----------------------------------------------------------\n",
    "try:\n",
    "    df_train = pd.read_csv('data/processed/train.csv')\n",
    "    df_val   = pd.read_csv('data/processed/val.csv')\n",
    "    df_test  = pd.read_csv('data/processed/test.csv')\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(\"âŒ Missing data files. Run 01 first.\")\n",
    "\n",
    "target_col = 'Target_Log1o2' if 'Target_Log1o2' in df_train.columns else 'Target'\n",
    "\n",
    "def get_Xy(df: pd.DataFrame):\n",
    "    y = df[target_col]\n",
    "    X = df.drop(columns=[target_col, 'SMILES_Meta', 'SMILES', 'ID'], errors='ignore')\n",
    "    X = X.select_dtypes(include=[np.number])\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = get_Xy(df_train)\n",
    "X_val,   y_val   = get_Xy(df_val)\n",
    "X_test,  y_test  = get_Xy(df_test)\n",
    "\n",
    "feat_cols = X_train.columns.tolist()\n",
    "X_val = X_val.reindex(columns=feat_cols).fillna(0)\n",
    "X_test = X_test.reindex(columns=feat_cols).fillna(0)\n",
    "\n",
    "print(f\"   Train: {X_train.shape} | Val: {X_val.shape} | Test: {X_test.shape}\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 2) å‚æ•°ç­–ç•¥é€‰æ‹©\n",
    "# ----------------------------------------------------------\n",
    "# STRATEGY = \"strict\"    # Depth=2, High Reg (æ¬ æ‹Ÿåˆé£é™©)\n",
    "# STRATEGY = \"balanced\"  # Depth=4, Mid Reg (å¯èƒ½è¿‡æ‹Ÿåˆ)\n",
    "STRATEGY = \"robust\"      # Depth=3, Low LR (ç¨³æ‰ç¨³æ‰“)\n",
    "\n",
    "print(f\"\\nğŸ”§ å½“å‰ç­–ç•¥: ã€{STRATEGY.upper()}ã€‘\")\n",
    "\n",
    "if STRATEGY == \"strict\":\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror', 'n_jobs': -1, 'random_state': 42,\n",
    "        'max_depth': 2, 'learning_rate': 0.02, 'n_estimators': 5000,\n",
    "        'min_child_weight': 6, 'gamma': 0.5,\n",
    "        'subsample': 0.6, 'colsample_bytree': 0.6,\n",
    "        'reg_alpha': 2.0, 'reg_lambda': 5.0,\n",
    "        'eval_metric': 'rmse'\n",
    "    }\n",
    "elif STRATEGY == \"balanced\":\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror', 'n_jobs': -1, 'random_state': 42,\n",
    "        'max_depth': 4, 'learning_rate': 0.05, 'n_estimators': 5000,\n",
    "        'min_child_weight': 3, 'gamma': 0.1,\n",
    "        'subsample': 0.8, 'colsample_bytree': 0.8,\n",
    "        'reg_alpha': 0.1, 'reg_lambda': 1.0,\n",
    "        'eval_metric': 'rmse'\n",
    "    }\n",
    "else: # robust (Default for QSAR/Chemistry)\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'n_jobs': -1,\n",
    "        'random_state': 42,\n",
    "\n",
    "        # --- é»„é‡‘å‚æ•°åŒº ---\n",
    "        'max_depth': 3,            # ç»å…¸æ·±åº¦\n",
    "        'learning_rate': 0.01,     # éå¸¸æ…¢çš„å­¦ä¹ ç‡ï¼Œé…åˆæ—©åœ\n",
    "        'n_estimators': 10000,     # ç»™è¶³ç©ºé—´è®©å®ƒæ…¢æ…¢è·‘\n",
    "\n",
    "        # --- å¼ºéšæœºæ€§ (å…³é”®) ---\n",
    "        'subsample': 0.7,          # æ¯æ¬¡åªçœ‹ 70% æ•°æ®\n",
    "        'colsample_bytree': 0.5,   # æ¯æ¬¡åªçœ‹ 50% ç‰¹å¾ (é˜²æ­¢è¿‡åº¦ä¾èµ–å•ä¸€ç‰¹å¾)\n",
    "\n",
    "        # --- é€‚åº¦æ­£åˆ™ ---\n",
    "        'min_child_weight': 5,     # ç¨å¾®æé«˜é—¨æ§›ï¼Œè¿‡æ»¤å™ªå£°\n",
    "        'gamma': 0.2,\n",
    "        'reg_alpha': 1.0,          # L1\n",
    "        'reg_lambda': 2.0,         # L2\n",
    "\n",
    "        'eval_metric': 'rmse'\n",
    "    }\n",
    "\n",
    "print(\"\\nğŸ§  Final Params:\")\n",
    "print(json.dumps({k: params[k] for k in ['max_depth', 'learning_rate', 'colsample_bytree', 'reg_alpha']}, indent=2))\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 3) è®­ç»ƒ (Train)\n",
    "# ----------------------------------------------------------\n",
    "print(\"\\n>>> Training with EarlyStopping on VAL ...\")\n",
    "\n",
    "model = XGBRegressor(**params, early_stopping_rounds=50)\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "    verbose=500\n",
    ")\n",
    "\n",
    "# å®‰å…¨è·å–æœ€ä½³è½®æ¬¡\n",
    "try:\n",
    "    best_iter = model.best_iteration\n",
    "except AttributeError:\n",
    "    try: best_iter = model.get_booster().best_iteration\n",
    "    except: best_iter = \"Unknown\"\n",
    "\n",
    "print(f\"\\nâœ… Done. Best Iteration: {best_iter}\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 4) é¢„æµ‹ & è¯„ä¼°\n",
    "# ----------------------------------------------------------\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_val   = model.predict(X_val)\n",
    "y_pred_test  = model.predict(X_test)\n",
    "\n",
    "def calc_r2(y, p): return r2_score(y, p)\n",
    "\n",
    "r2_tr = calc_r2(y_train, y_pred_train)\n",
    "r2_va = calc_r2(y_val, y_pred_val)\n",
    "r2_te = calc_r2(y_test, y_pred_test)\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(f\"ğŸ“Š Performance ({STRATEGY.title()} Mode)\")\n",
    "print(f\"   Train: {r2_tr:.4f}\")\n",
    "print(f\"   Val  : {r2_va:.4f}\")\n",
    "print(f\"   Test : {r2_te:.4f}\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 5) è¯Šæ–­: ç‰¹å¾é‡è¦æ€§ (æ–°å¢åŠŸèƒ½)\n",
    "# ----------------------------------------------------------\n",
    "# å¦‚æœæ•ˆæœè¿˜æ˜¯å¾ˆå·®ï¼Œçœ‹çœ‹æ¨¡å‹åˆ°åº•åœ¨å­¦ä»€ä¹ˆ\n",
    "try:\n",
    "    importance = model.feature_importances_\n",
    "    feats = X_train.columns\n",
    "    df_imp = pd.DataFrame({'Feature': feats, 'Importance': importance}).sort_values('Importance', ascending=False)\n",
    "    print(\"\\nğŸ§ Top 10 Features Used by Model:\")\n",
    "    print(df_imp.head(10).to_string(index=False))\n",
    "except:\n",
    "    print(\"\\nâš ï¸ æ— æ³•æ‰“å°ç‰¹å¾é‡è¦æ€§\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 6) ä¿å­˜ç»“æœ\n",
    "# ----------------------------------------------------------\n",
    "os.makedirs('results/predictions', exist_ok=True)\n",
    "pd.DataFrame({target_col: y_train.values, 'Predicted': y_pred_train}).to_csv('results/predictions/train_predictions.csv', index=False)\n",
    "pd.DataFrame({target_col: y_val.values, 'Predicted': y_pred_val}).to_csv('results/predictions/val_predictions.csv', index=False)\n",
    "pd.DataFrame({target_col: y_test.values, 'Predicted': y_pred_test}).to_csv('results/predictions/final_predictions.csv', index=False)\n",
    "\n",
    "print(\"\\nğŸ’¾ é¢„æµ‹ç»“æœå·²ä¿å­˜ã€‚\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
