{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c34e0e7180381709",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-24T13:59:47.017656Z",
     "iopub.status.busy": "2026-01-24T13:59:47.017656Z",
     "iopub.status.idle": "2026-01-24T13:59:48.114076Z",
     "shell.execute_reply": "2026-01-24T13:59:48.114076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ [03] å¯åŠ¨ XGB è®­ç»ƒ (CDFT å®Œæ•´ç‰ˆ) | å½“å‰ç›®å½•: D:\\HO\\my_smiles_project\\y_g.baby\\project_cdft\n",
      "\n",
      ">>> [Step 1] Loading Data...\n",
      "   Train: (105, 23) | Val: (23, 23) | Test: (23, 23)\n",
      "   ç‰¹å¾æ•°é‡: 23\n",
      "\n",
      ">>> [Step 2] Loading Parameters...\n",
      "   âœ… æˆåŠŸè¯»å– 02 å·å‚æ•°æ–‡ä»¶ (7 ä¸ªå‚æ•°)\n",
      "\n",
      "ğŸ§  æœ€ç»ˆè®­ç»ƒå‚æ•°:\n",
      "   LR: 0.021371153508685993 | Depth: 2 | EarlyStop: 100\n",
      "\n",
      ">>> [Step 3] Training Model...\n",
      "[0]\tvalidation_0-rmse:1.58265\tvalidation_1-rmse:1.79010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[85]\tvalidation_0-rmse:0.92179\tvalidation_1-rmse:1.26949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… è®­ç»ƒå®Œæˆ! æœ€ä½³è¿­ä»£è½®æ•°: 78\n",
      "\n",
      ">>> [Step 4] Predicting & Evaluating...\n",
      "\n",
      "========================================\n",
      "ğŸ“Š Performance Report (CDFT)\n",
      "   Train: R2=0.6531 | RMSE=0.9424\n",
      "   Val  : R2=0.4894 | RMSE=1.2632\n",
      "   Test : R2=0.5121 | RMSE=1.2929\n",
      "========================================\n",
      "âš ï¸  è¯Šæ–­: å¯èƒ½å­˜åœ¨è¿‡æ‹Ÿåˆ (Train >> Val)ï¼Œå»ºè®®å¢åŠ æ­£åˆ™åŒ–æˆ–å‡å°‘æ ‘æ·±ã€‚\n",
      "\n",
      ">>> [Step 5] Saving Results...\n",
      "ğŸ’¾ é¢„æµ‹ç»“æœå·²ä¿å­˜è‡³ results/predictions/ (Train/Val/Final)\n",
      "ğŸ’¾ ç‰¹å¾é‡è¦æ€§å·²ä¿å­˜è‡³ results/analysis/feature_importance_xgb.csv\n",
      "\n",
      "ğŸ§ª Top 5 æœ€é‡è¦ç‰¹å¾ (Top Drivers):\n",
      "                   Feature  Importance\n",
      "          Vertical IP (eV)    0.205784\n",
      "Nucleophilicity index (eV)    0.154000\n",
      "             Hardness (eV)    0.089728\n",
      "            E-HOMO(N) (eV)    0.075823\n",
      "          E-HOMO(N+1) (eV)    0.048068\n",
      "\n",
      "âœ… æ‰€æœ‰æ­¥éª¤å®Œæˆï¼è¯·è¿è¡Œ 04_visualization.ipynb æŸ¥çœ‹å›¾è¡¨ã€‚\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# File: project_cdft/notebooks/03_final_training_xgb.ipynb\n",
    "# ==========================================\n",
    "# [CDFT-only] Final Training + Predictions (Ultimate Full Version)\n",
    "#\n",
    "# æ ¸å¿ƒåŠŸèƒ½:\n",
    "# 1. è¯»å– 01 ç”Ÿæˆçš„ Train/Val/Test æ•°æ®\n",
    "# 2. è¯»å– 02 ç”Ÿæˆçš„ best_params_xgb.json (æ™ºèƒ½æ¸…æ´— regressor__xgb__ å‰ç¼€)\n",
    "# 3. è®­ç»ƒ XGBoost (å…¼å®¹ sklearn æ¥å£ï¼Œè§£å†³ early_stopping_rounds æŠ¥é”™)\n",
    "# 4. ç”Ÿæˆä¸‰ä»½é¢„æµ‹ç»“æœ (train/val/final) ä¾› 04 ç»˜å›¾\n",
    "# 5. è¾“å‡ºç‰¹å¾é‡è¦æ€§ (Feature Importance)\n",
    "\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 0) ç¯å¢ƒä¸è·¯å¾„å‡†å¤‡\n",
    "# ----------------------------------------------------------\n",
    "# ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹è¿è¡Œ\n",
    "if 'notebooks' in os.getcwd():\n",
    "    os.chdir('..')\n",
    "print(f\"ğŸš€ [03] å¯åŠ¨ XGB è®­ç»ƒ (CDFT å®Œæ•´ç‰ˆ) | å½“å‰ç›®å½•: {os.getcwd()}\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 1) æ•°æ®è¯»å– (Data Loading)\n",
    "# ----------------------------------------------------------\n",
    "print(\"\\n>>> [Step 1] Loading Data...\")\n",
    "try:\n",
    "    df_train = pd.read_csv('data/processed/train.csv')\n",
    "    df_val   = pd.read_csv('data/processed/val.csv')\n",
    "    df_test  = pd.read_csv('data/processed/test.csv')\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(\"âŒ æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶ï¼è¯·å…ˆè¿è¡Œ 01_feature_engineering.ipynb\")\n",
    "\n",
    "# è‡ªåŠ¨è¯†åˆ« Target åˆ—\n",
    "target_col = 'Target_Log1o2' if 'Target_Log1o2' in df_train.columns else 'Target'\n",
    "\n",
    "# å®šä¹‰æ•°æ®æå–å‡½æ•°\n",
    "def get_Xy(df: pd.DataFrame):\n",
    "    y = df[target_col]\n",
    "    # æ’é™¤éç‰¹å¾åˆ— (Target, SMILES, IDç­‰)\n",
    "    X = df.drop(columns=[target_col, 'SMILES_Meta', 'SMILES', 'ID'], errors='ignore')\n",
    "    # åªä¿ç•™æ•°å€¼å‹ç‰¹å¾\n",
    "    X = X.select_dtypes(include=[np.number])\n",
    "    return X, y\n",
    "\n",
    "# æå– X å’Œ y\n",
    "X_train, y_train = get_Xy(df_train)\n",
    "X_val,   y_val   = get_Xy(df_val)\n",
    "X_test,  y_test  = get_Xy(df_test)\n",
    "\n",
    "feature_names = list(X_train.columns)\n",
    "print(f\"   Train: {X_train.shape} | Val: {X_val.shape} | Test: {X_test.shape}\")\n",
    "print(f\"   ç‰¹å¾æ•°é‡: {len(feature_names)}\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 2) å‚æ•°è¯»å–ä¸æ¸…æ´— (Params Loading)\n",
    "# ----------------------------------------------------------\n",
    "print(\"\\n>>> [Step 2] Loading Parameters...\")\n",
    "PARAM_FILE = 'results/models/best_params_xgb.json'\n",
    "params = {}\n",
    "\n",
    "# å°è¯•è¯»å– 02 å·æ–‡ä»¶ç”Ÿæˆçš„å‚æ•°\n",
    "if os.path.exists(PARAM_FILE):\n",
    "    try:\n",
    "        raw = json.load(open(PARAM_FILE, 'r', encoding='utf-8'))\n",
    "        print(f\"   âœ… æˆåŠŸè¯»å– 02 å·å‚æ•°æ–‡ä»¶ ({len(raw)} ä¸ªå‚æ•°)\")\n",
    "\n",
    "        # â˜…â˜…â˜… æ™ºèƒ½æ¸…æ´—å‰ç¼€ â˜…â˜…â˜…\n",
    "        # 02å·æ–‡ä»¶å¯èƒ½å¸¦æœ‰ regressor__xgb__ æˆ– xgb__ å‰ç¼€ï¼Œå¿…é¡»å»æ‰æ‰èƒ½ç»™ XGBRegressor ç”¨\n",
    "        for k, v in raw.items():\n",
    "            # æ— è®ºå‰ç¼€æ˜¯ regressor__xgb__ è¿˜æ˜¯ xgb__ï¼Œå–æœ€åä¸€éƒ¨åˆ†ä½œä¸ºå‚æ•°å\n",
    "            clean_key = k.split('xgb__')[-1]\n",
    "            params[clean_key] = v\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   âš ï¸ å‚æ•°æ–‡ä»¶è¯»å–å¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨é»˜è®¤å‚æ•°ã€‚\")\n",
    "else:\n",
    "    print(\"   âš ï¸ æœªæ‰¾åˆ°å‚æ•°æ–‡ä»¶ï¼Œå°†ä½¿ç”¨é»˜è®¤å‚æ•°ã€‚\")\n",
    "\n",
    "# è®¾ç½®é»˜è®¤å‚æ•° (CDFT å°æ ·æœ¬ç¨³å¥é…ç½®)\n",
    "# å¦‚æœ params é‡Œå·²ç»æœ‰äº†(æ¥è‡ª02)ï¼Œsetdefault ä¸ä¼šè¦†ç›–å®ƒ\n",
    "defaults = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'n_jobs': -1,\n",
    "    'random_state': 42,\n",
    "\n",
    "    # åŸºç¡€ç»“æ„\n",
    "    'max_depth': 3,            # æµ…æ ‘é˜²è¿‡æ‹Ÿåˆ\n",
    "    'learning_rate': 0.05,     # æ…¢å·¥å‡ºç»†æ´»\n",
    "    'n_estimators': 5000,      # ç»™è¶³ç©ºé—´ï¼Œé æ—©åœæ§åˆ¶\n",
    "\n",
    "    # æŠ—å™ªæœºåˆ¶\n",
    "    'subsample': 0.75,         # è¡Œé‡‡æ ·\n",
    "    'colsample_bytree': 0.8,   # åˆ—é‡‡æ ·\n",
    "    'reg_alpha': 0.1,          # L1 æ­£åˆ™\n",
    "    'reg_lambda': 1.0          # L2 æ­£åˆ™\n",
    "}\n",
    "\n",
    "for k, v in defaults.items():\n",
    "    params.setdefault(k, v)\n",
    "\n",
    "# â˜…â˜…â˜… ç»ˆæå…¼å®¹æ€§ä¿®å¤ â˜…â˜…â˜…\n",
    "# å°† early_stopping_rounds å’Œ eval_metric æ”¾å…¥åˆå§‹åŒ–å‚æ•°ä¸­\n",
    "# è¿™æ ·å¯ä»¥é¿å…åœ¨ fit() ä¸­ä¼ å‚å¯¼è‡´çš„ TypeError\n",
    "params['early_stopping_rounds'] = 100\n",
    "params['eval_metric'] = 'rmse'\n",
    "\n",
    "print(f\"\\nğŸ§  æœ€ç»ˆè®­ç»ƒå‚æ•°:\")\n",
    "print(f\"   LR: {params['learning_rate']} | Depth: {params['max_depth']} | EarlyStop: {params['early_stopping_rounds']}\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 3) æ¨¡å‹è®­ç»ƒ (Training)\n",
    "# ----------------------------------------------------------\n",
    "print(\"\\n>>> [Step 3] Training Model...\")\n",
    "\n",
    "# åˆå§‹åŒ–æ¨¡å‹\n",
    "model = XGBRegressor(**params)\n",
    "\n",
    "# è®­ç»ƒ (fit ä¸­åªä¼ æ•°æ®å’Œ eval_setï¼Œä¸ä¼  callbacks)\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "    verbose=500  # æ¯500è½®æ‰“å°ä¸€æ¬¡è¿›åº¦\n",
    ")\n",
    "\n",
    "# è·å–æœ€ä½³è¿­ä»£è½®æ•° (å…¼å®¹ä¸åŒç‰ˆæœ¬)\n",
    "best_iter = getattr(model, \"best_iteration\", params['n_estimators'])\n",
    "print(f\"\\nâœ… è®­ç»ƒå®Œæˆ! æœ€ä½³è¿­ä»£è½®æ•°: {best_iter}\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 4) é¢„æµ‹ä¸è¯„ä¼° (Prediction & Evaluation)\n",
    "# ----------------------------------------------------------\n",
    "print(\"\\n>>> [Step 4] Predicting & Evaluating...\")\n",
    "\n",
    "def get_metrics(name, y_true, y_pred):\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    return r2, rmse\n",
    "\n",
    "# é¢„æµ‹\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_val   = model.predict(X_val)\n",
    "y_pred_test  = model.predict(X_test)\n",
    "\n",
    "# è®¡ç®—æŒ‡æ ‡\n",
    "r2_tr, rmse_tr = get_metrics(\"train\", y_train, y_pred_train)\n",
    "r2_va, rmse_va = get_metrics(\"val\",   y_val,   y_pred_val)\n",
    "r2_te, rmse_te = get_metrics(\"test\",  y_test,  y_pred_test)\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"ğŸ“Š Performance Report (CDFT)\")\n",
    "print(f\"   Train: R2={r2_tr:.4f} | RMSE={rmse_tr:.4f}\")\n",
    "print(f\"   Val  : R2={r2_va:.4f} | RMSE={rmse_va:.4f}\")\n",
    "print(f\"   Test : R2={r2_te:.4f} | RMSE={rmse_te:.4f}\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# ç®€å•è¯Šæ–­\n",
    "if r2_tr - r2_va > 0.15:\n",
    "    print(\"âš ï¸  è¯Šæ–­: å¯èƒ½å­˜åœ¨è¿‡æ‹Ÿåˆ (Train >> Val)ï¼Œå»ºè®®å¢åŠ æ­£åˆ™åŒ–æˆ–å‡å°‘æ ‘æ·±ã€‚\")\n",
    "elif r2_va < 0.5:\n",
    "    print(\"âš ï¸  è¯Šæ–­: å¯èƒ½å­˜åœ¨æ¬ æ‹Ÿåˆ (Val R2 ä½)ï¼Œå»ºè®®æ£€æŸ¥ç‰¹å¾è´¨é‡æˆ–é™ä½å­¦ä¹ ç‡ã€‚\")\n",
    "else:\n",
    "    print(\"âœ¨ è¯Šæ–­: æ¨¡å‹å¹³è¡¡æ€§è‰¯å¥½ï¼\")\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 5) ç»“æœä¿å­˜ (Saving)\n",
    "# ----------------------------------------------------------\n",
    "print(\"\\n>>> [Step 5] Saving Results...\")\n",
    "os.makedirs('results/predictions', exist_ok=True)\n",
    "\n",
    "# ä¿å­˜é¢„æµ‹ç»“æœ (04å·æ–‡ä»¶éœ€è¦)\n",
    "pd.DataFrame({target_col: y_train, 'Predicted': y_pred_train}).to_csv('results/predictions/train_predictions.csv', index=False)\n",
    "pd.DataFrame({target_col: y_val,   'Predicted': y_pred_val}).to_csv('results/predictions/val_predictions.csv', index=False)\n",
    "pd.DataFrame({target_col: y_test,  'Predicted': y_pred_test}).to_csv('results/predictions/final_predictions.csv', index=False)\n",
    "print(\"ğŸ’¾ é¢„æµ‹ç»“æœå·²ä¿å­˜è‡³ results/predictions/ (Train/Val/Final)\")\n",
    "\n",
    "# ä¿å­˜ç‰¹å¾é‡è¦æ€§ (Feature Importance)\n",
    "try:\n",
    "    os.makedirs('results/analysis', exist_ok=True)\n",
    "    fi_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "\n",
    "    fi_path = 'results/analysis/feature_importance_xgb.csv'\n",
    "    fi_df.to_csv(fi_path, index=False)\n",
    "    print(f\"ğŸ’¾ ç‰¹å¾é‡è¦æ€§å·²ä¿å­˜è‡³ {fi_path}\")\n",
    "\n",
    "    print(\"\\nğŸ§ª Top 5 æœ€é‡è¦ç‰¹å¾ (Top Drivers):\")\n",
    "    print(fi_df.head(5).to_string(index=False))\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ç‰¹å¾é‡è¦æ€§ä¿å­˜å¤±è´¥: {e}\")\n",
    "\n",
    "print(\"\\nâœ… æ‰€æœ‰æ­¥éª¤å®Œæˆï¼è¯·è¿è¡Œ 04_visualization.ipynb æŸ¥çœ‹å›¾è¡¨ã€‚\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
